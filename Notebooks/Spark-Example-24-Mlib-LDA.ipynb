{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA topic modelling\n",
    "The notebook on LDA topic modelling for IMDB dataset using PySpark is a comprehensive guide that demonstrates how to perform topic modelling using Latent Dirichlet Allocation (LDA) in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('Spark-Example-30-ChatGPT') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some warnings, so we suppress them\n",
    "import warnings\n",
    "from pyspark.sql import functions as F\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                text|sentiment|\n",
      "+--------------------+---------+\n",
      "|One of the other ...| positive|\n",
      "|A wonderful littl...| positive|\n",
      "|I thought this wa...| positive|\n",
      "+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "tFile=\"data\\IMDB Dataset.csv.bz2\"\n",
    "df = spark.read.csv(tFile,header=True,inferSchema=True )\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(.2, seed=100)\n",
    "#df= df.where(F.col(\"sentiment\")==\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "| positive| 5067|\n",
      "| negative| 4993|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production  The filming tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably   all time favorite movie    story   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like   see   resurrection       d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was   amazing  fresh  innovative ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The cast played Shakespeare Shakespeare lost  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment   \n",
       "0  A wonderful little production. <br /><br />The...  positive  \\\n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  The cast played Shakespeare.<br /><br />Shakes...  negative   \n",
       "\n",
       "                                              text_c  \n",
       "0    wonderful little production  The filming tec...  \n",
       "1  Probably   all time favorite movie    story   ...  \n",
       "2    sure would like   see   resurrection       d...  \n",
       "3  This show was   amazing  fresh  innovative ide...  \n",
       "4  The cast played Shakespeare Shakespeare lost  ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove html tags from text\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(F.col(\"text\"), r'<[^>]+>', \"\"));\n",
    "# Remove non-letters\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(\"text_c\", r\"[\\.\\!\\,\\-\\']\", \" \"))\n",
    "# Remove non-letters\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(\"text_c\", r\"[^a-zA-Z\\ ]\", \"\"))\n",
    "# Remove words 1, 2 char\n",
    "df = df.withColumn(\"text_c\", F.regexp_replace(\"text_c\", r\"\\b\\w{1,2}\\b\", \" \"))\n",
    "df.toPandas().head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization (optional)\n",
    "Lemmatization is the process of reducing a word to its base or root form, which is also known as a lemma. The purpose of lemmatization is to simplify text and make it easier to analyze by grouping together different forms of the same word. For example, the words \"running,\" \"ran,\" and \"runs\" can all be reduced to the base form \"run\" through lemmatization. \n",
    "\n",
    "However, lemmatization can be a **time-consuming operation**, especially when dealing with large amounts of text data. This is because the process involves analyzing each word in a text and identifying its base form. It also requires a comprehensive understanding of the grammatical rules of a language to accurately identify the correct lemma for each word.\n",
    "\n",
    "Despite its time-consuming nature, lemmatization can be a powerful tool in natural language processing and text analysis. It can help with tasks such as sentiment analysis, topic modeling, and text classification. When using lemmatization, it's important to use it carefully and correctly to ensure that the text is properly processed and analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# from pyspark.sql.functions import udf\n",
    "# from pyspark.sql.types import StringType\n",
    "\n",
    "\n",
    "# # Load the spaCy model\n",
    "# nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# # Define a function to apply the lemmatizer to a text\n",
    "# @udf(returnType=StringType())\n",
    "# def lemmatize_text(text):\n",
    "#     doc = nlp(text)\n",
    "#     lemmas = [token.lemma_ for token in doc]\n",
    "#     print(lemmas)\n",
    "#     return \" \".join(lemmas)\n",
    "\n",
    "# # Define a UDF to apply the lemmatizer to a column\n",
    "# # def l(text):\n",
    "# #     return text\n",
    "# # lemmatize_udf = udf(l, StringType())\n",
    "\n",
    "# # Apply the UDF to a DataFrame column\n",
    "# df0 = df.withColumn(\"text_c\", lemmatize_text(\"text_c\"))\n",
    "# df0.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizer,IDF\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline\n",
    "Preprocessing pipeline for text classification using LDA may include the following steps:\n",
    "\n",
    "- Tokenization: This step involves breaking the text into individual words or tokens. A tokenizer can split the text into tokens based on spaces, punctuation, and other delimiters.\n",
    "- Stop words removal: This step involves removing commonly used words in a language that do not carry much meaning or contribute to the topic of the text, such as \"the\", \"and\", \"is\". Stop words removal helps to reduce the size of the vocabulary and improves the efficiency of subsequent steps.\n",
    "- Count vectorizer: This step involves converting the tokenized text into a matrix of word counts. Each row represents a document, and each column represents a unique word in the vocabulary. The values in the matrix represent the frequency of each word in each document.\n",
    "- IDF (Inverse Document Frequency): This step involves weighting the word counts to account for the frequency of each word in the entire corpus. Words that occur frequently across all documents are given a lower weight, while words that occur rarely are given a higher weight.\n",
    "\n",
    "By using IDF, the weight of each word is inversely proportional to the number of documents that contain that word. This helps to identify the important words that are specific to a particular document and can help to distinguish between different topics.\n",
    "\n",
    "Once these steps are completed, the resulting TF-IDF vectors can be used as input for the LDA algorithm to identify the underlying topics in the text corpus and classify the documents based on their topic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "#Run 1 Use 500 words\n",
    "#countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=500)\n",
    "# Run 2 Use 1000 words\n",
    "# countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000)\n",
    "# Run 3 Use Filter most frequent words\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000,minDF=10, maxDF=5000)\n",
    "\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, countVectorizer,idf])\n",
    "data_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'good', 'even', 'time', 'story', 'see', 'really', 'well', 'much', 'people', 'get', 'also', 'bad', 'great', 'first', 'made', 'make', 'movies', 'way', 'characters', 'think', 'character', 'watch', 'films', 'two', 'seen', 'life', 'best', 'many', 'show', 'never', 'love', 'plot', 'acting', 'know', 'little', 'ever', 'better', 'still', 'man', 'end', 'say', 'scenes', 'scene', 'back', 'something', 'real', 'thing', 'didn', 'funny', 'actors', 'watching', 'years', 'another', 'work', 'doesn', 'look', 'though', 'old', 'director', 'going', 'nothing', 'actually', 'find', 'makes', 'every', 'new', 'lot', 'part', 'world', 'seems', 'pretty', 'things', 'want', 'young', 'however', 'enough', 'fact', 'cast', 'around', 'quite', 'big', 'horror', 'long', 'take', 'got', 'may', 'without', 'give', 'music', 'action', 'comedy', 'series', 'saw', 'almost', 'role', 'right', 'always', 'must', 'gets']\n"
     ]
    }
   ],
   "source": [
    "# Print the vocabulary\n",
    "vocabulary = data_model.stages[2].vocabulary\n",
    "print(vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_c</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>features_c</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10055</th>\n",
       "      <td>As someone who loves baseball history, especia...</td>\n",
       "      <td>negative</td>\n",
       "      <td>someone who loves baseball history  especial...</td>\n",
       "      <td>[, , someone, who, loves, baseball, history, ,...</td>\n",
       "      <td>[, , someone, loves, baseball, history, , espe...</td>\n",
       "      <td>(1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.7619554807841183, 0.0, 1.0810748933853436, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10056</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;Headlines warn us of the current c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Headlines warn     the current campaign   demo...</td>\n",
       "      <td>[headlines, warn, , , , , the, current, campai...</td>\n",
       "      <td>[headlines, warn, , , , , current, campaign, ,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 2.2319139025253767, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10057</th>\n",
       "      <td>Dog Bite Dog isn't going to be for everyone, b...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Dog Bite Dog isn   going     for everyone  but...</td>\n",
       "      <td>[dog, bite, dog, isn, , , going, , , , , for, ...</td>\n",
       "      <td>[dog, bite, dog, isn, , , going, , , , , every...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>(0.0, 0.9678927174918324, 0.0, 0.0, 1.22044136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10058</th>\n",
       "      <td>This is your typical junk comedy.&lt;br /&gt;&lt;br /&gt;T...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This   your typical junk comedy There are almo...</td>\n",
       "      <td>[this, , , your, typical, junk, comedy, there,...</td>\n",
       "      <td>[, , typical, junk, comedy, almost, , , laughs...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10059</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought this movie did   down right good job...</td>\n",
       "      <td>[, , thought, this, movie, did, , , down, righ...</td>\n",
       "      <td>[, , thought, movie, , , right, good, job, , ,...</td>\n",
       "      <td>(2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.5239109615682367, 0.9678927174918324, 1.081...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment   \n",
       "10055  As someone who loves baseball history, especia...  negative  \\\n",
       "10056  <br /><br />Headlines warn us of the current c...  positive   \n",
       "10057  Dog Bite Dog isn't going to be for everyone, b...  positive   \n",
       "10058  This is your typical junk comedy.<br /><br />T...  negative   \n",
       "10059  I thought this movie did a down right good job...  positive   \n",
       "\n",
       "                                                  text_c   \n",
       "10055    someone who loves baseball history  especial...  \\\n",
       "10056  Headlines warn     the current campaign   demo...   \n",
       "10057  Dog Bite Dog isn   going     for everyone  but...   \n",
       "10058  This   your typical junk comedy There are almo...   \n",
       "10059    thought this movie did   down right good job...   \n",
       "\n",
       "                                                   words   \n",
       "10055  [, , someone, who, loves, baseball, history, ,...  \\\n",
       "10056  [headlines, warn, , , , , the, current, campai...   \n",
       "10057  [dog, bite, dog, isn, , , going, , , , , for, ...   \n",
       "10058  [this, , , your, typical, junk, comedy, there,...   \n",
       "10059  [, , thought, this, movie, did, , , down, righ...   \n",
       "\n",
       "                                                filtered   \n",
       "10055  [, , someone, loves, baseball, history, , espe...  \\\n",
       "10056  [headlines, warn, , , , , current, campaign, ,...   \n",
       "10057  [dog, bite, dog, isn, , , going, , , , , every...   \n",
       "10058  [, , typical, junk, comedy, almost, , , laughs...   \n",
       "10059  [, , thought, movie, , , right, good, job, , ,...   \n",
       "\n",
       "                                              features_c   \n",
       "10055  (1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...  \\\n",
       "10056  (0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, ...   \n",
       "10057  (0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "10058  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "10059  (2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                features  \n",
       "10055  (0.7619554807841183, 0.0, 1.0810748933853436, ...  \n",
       "10056  (0.0, 0.0, 0.0, 0.0, 0.0, 2.2319139025253767, ...  \n",
       "10057  (0.0, 0.9678927174918324, 0.0, 0.0, 1.22044136...  \n",
       "10058  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "10059  (1.5239109615682367, 0.9678927174918324, 1.081...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the dataset using the preprocessing pipeline\n",
    "dataset = data_model.transform(df)\n",
    "dataset.toPandas().tail(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA\n",
    "LDA (Latent Dirichlet Allocation) is a topic modeling technique that is used to identify the underlying topics within a large collection of text documents. It is a probabilistic model that assumes each document is a mixture of several topics and each topic is a mixture of several words.\n",
    "- The LDA algorithm works by first randomly assigning each word in each document to a topic. It then iteratively improves these assignments by reassigning words to topics based on the probability of the word belonging to each topic, and the probability of each document belonging to each topic.\n",
    "- The output of the LDA algorithm is a set of topics, each represented by a distribution over words, and a set of document-topic distributions, which represent the degree to which each document belongs to each topic.\n",
    "- LDA can be used for a wide range of applications, such as content analysis, information retrieval, and recommendation systems. It has been widely applied in fields such as social media analysis, e-commerce, and market research.\n",
    "- One of the main advantages of LDA is that it can automatically identify the topics present in a corpus without any prior knowledge of the topics. This makes it a useful tool for analyzing large and complex datasets.\n",
    "- However, LDA has some limitations. It may not work well with short documents, and it may require a large amount of data to accurately estimate the topic distributions. Additionally, the interpretation of the resulting topics may require human expertise and domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find two topics\n",
    "lda = LDA(k=2, maxIter=20)\n",
    "model = lda.fit(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics Matrix\n",
    "Inferred topics, where each topic is represented by a distribution over terms. This is a matrix of size $vocabSize$ x $k$, where each column is a topic. No guarantees are given about the ordering of the topics.\n",
    "\n",
    "Warning: If this model is actually a DistributedLDAModel instance produced by the Expectation-Maximization (“em”) optimizer, then this method could involve collecting a large amount of data to the driver (on the order of $vocabSize$ x $k$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1539.51100926, 1097.49991974],\n",
       "       [1397.53296922, 1134.30655168],\n",
       "       [1608.33821227,  879.87489191],\n",
       "       ...,\n",
       "       [ 258.15087611,  139.07039458],\n",
       "       [ 191.05545825,  138.92294799],\n",
       "       [  89.0453827 ,  291.51450267]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the LDA transformation matrix\n",
    "print(model.topicsMatrix().toArray().shape)\n",
    "model.topicsMatrix().toArray()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe topics\n",
    "Return the topics described by weighted terms. Each topic is represented as a pair of matching arrays: (term indices, term weights in topic). Each topic’s terms are sorted in order of decreasing weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[29, 12, 2, 0, 1]</td>\n",
       "      <td>[0.004966077947949943, 0.004851071687178882, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[4, 39, 26, 31, 11]</td>\n",
       "      <td>[0.004070769083471874, 0.00386849623160023, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic          termIndices   \n",
       "0      0    [29, 12, 2, 0, 1]  \\\n",
       "1      1  [4, 39, 26, 31, 11]   \n",
       "\n",
       "                                         termWeights  \n",
       "0  [0.004966077947949943, 0.004851071687178882, 0...  \n",
       "1  [0.004070769083471874, 0.00386849623160023, 0....  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "topics = model.describeTopics(5)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['show', 'bad', 'even', 'like', 'good', 'really', 'movies', 'see', 'made', 'watch', 'get', 'make', 'time', 'acting', 'funny', 'seen', 'people', 'ever', 'never', 'say', 'think', 'better', 'much', 'well', 'know', 'horror', 'first', 'great', 'nothing', 'story']\n",
      "['story', 'man', 'life', 'love', 'also', 'time', 'films', 'people', 'well', 'two', 'much', 'great', 'good', 'best', 'like', 'many', 'character', 'first', 'really', 'characters', 'way', 'young', 'still', 'see', 'end', 'father', 'world', 'little', 'wife', 'new']\n"
     ]
    }
   ],
   "source": [
    "# Print most important words per topic\n",
    "topics = model.describeTopics(30)\n",
    "for r in topics.select(\"termIndices\").collect():\n",
    "    rez = []\n",
    "    for l in r:\n",
    "        for i in l:\n",
    "            rez.append(vocabulary[i])\n",
    "    print(rez[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LDA model wiht ten topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text_c\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered\")\n",
    "# Run 1: Use all the words\n",
    "# countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000)\n",
    "# Run 2: Discard the very frequent words\n",
    "countVectorizer = CountVectorizer(inputCol=remover.getOutputCol(), outputCol=\"features_c\", vocabSize=1000,minDF=10, maxDF=3000)\n",
    "\n",
    "idf = IDF(inputCol=countVectorizer.getOutputCol(), outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tokenizer,remover, countVectorizer,idf])\n",
    "data_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['story', 'much', 'people', 'get', 'also', 'bad', 'great', 'first', 'made', 'make', 'movies', 'way', 'characters', 'think', 'character', 'watch', 'films', 'two', 'seen', 'life', 'best', 'many', 'show', 'never', 'love', 'plot', 'acting', 'know', 'little', 'ever', 'better', 'still', 'man', 'end', 'say', 'scenes', 'scene', 'back', 'something', 'real', 'thing', 'didn', 'funny', 'actors', 'watching', 'years', 'another', 'work', 'doesn', 'though', 'look', 'old', 'director', 'going', 'nothing', 'actually', 'find', 'makes', 'every', 'new', 'lot', 'part', 'world', 'seems', 'pretty', 'things', 'want', 'however', 'young', 'enough', 'fact', 'cast', 'around', 'quite', 'big', 'horror', 'long', 'take', 'got', 'may', 'without', 'give', 'music', 'action', 'comedy', 'series', 'saw', 'almost', 'role', 'right', 'always', 'must', 'gets', 'interesting', 'times', 'thought', 'least', 'done', 'guy', 'far']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = data_model.stages[2].vocabulary\n",
    "print(vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_c</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered</th>\n",
       "      <th>features_c</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production  The filming tec...</td>\n",
       "      <td>[, , wonderful, little, production, , the, fil...</td>\n",
       "      <td>[, , wonderful, little, production, , filming,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3659286614209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably   all time favorite movie    story   ...</td>\n",
       "      <td>[probably, , , all, time, favorite, movie, , ,...</td>\n",
       "      <td>[probably, , , time, favorite, movie, , , , st...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(1.2204413675282908, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>sure would like   see   resurrection       d...</td>\n",
       "      <td>[, , sure, would, like, , , see, , , resurrect...</td>\n",
       "      <td>[, , sure, like, , , see, , , resurrection, , ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was   amazing  fresh  innovative ide...</td>\n",
       "      <td>[this, show, was, , , amazing, , fresh, , inno...</td>\n",
       "      <td>[show, , , amazing, , fresh, , innovative, ide...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 1.358554282960248, 2.9161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>The cast played Shakespeare Shakespeare lost  ...</td>\n",
       "      <td>[the, cast, played, shakespeare, shakespeare, ...</td>\n",
       "      <td>[cast, played, shakespeare, shakespeare, lost,...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment   \n",
       "0  A wonderful little production. <br /><br />The...  positive  \\\n",
       "1  Probably my all-time favorite movie, a story o...  positive   \n",
       "2  I sure would like to see a resurrection of a u...  positive   \n",
       "3  This show was an amazing, fresh & innovative i...  negative   \n",
       "4  The cast played Shakespeare.<br /><br />Shakes...  negative   \n",
       "\n",
       "                                              text_c   \n",
       "0    wonderful little production  The filming tec...  \\\n",
       "1  Probably   all time favorite movie    story   ...   \n",
       "2    sure would like   see   resurrection       d...   \n",
       "3  This show was   amazing  fresh  innovative ide...   \n",
       "4  The cast played Shakespeare Shakespeare lost  ...   \n",
       "\n",
       "                                               words   \n",
       "0  [, , wonderful, little, production, , the, fil...  \\\n",
       "1  [probably, , , all, time, favorite, movie, , ,...   \n",
       "2  [, , sure, would, like, , , see, , , resurrect...   \n",
       "3  [this, show, was, , , amazing, , fresh, , inno...   \n",
       "4  [the, cast, played, shakespeare, shakespeare, ...   \n",
       "\n",
       "                                            filtered   \n",
       "0  [, , wonderful, little, production, , filming,...  \\\n",
       "1  [probably, , , time, favorite, movie, , , , st...   \n",
       "2  [, , sure, like, , , see, , , resurrection, , ...   \n",
       "3  [show, , , amazing, , fresh, , innovative, ide...   \n",
       "4  [cast, played, shakespeare, shakespeare, lost,...   \n",
       "\n",
       "                                          features_c   \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \\\n",
       "1  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  (0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, ...   \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                            features  \n",
       "0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3659286614209...  \n",
       "1  (1.2204413675282908, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  (0.0, 0.0, 0.0, 0.0, 1.358554282960248, 2.9161...  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data_model.transform(df)\n",
    "dataset.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find two topics\n",
    "lda = LDA(k=10, maxIter=20)\n",
    "model = lda.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[178, 501, 16, 62, 160]</td>\n",
       "      <td>[0.017475817288113468, 0.008052443968767586, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[300, 130, 42, 84, 426]</td>\n",
       "      <td>[0.007347377651882966, 0.0072655290516734005, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[5, 136, 10, 29, 251]</td>\n",
       "      <td>[0.008795192147850545, 0.006622747467534118, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[22, 244, 85, 637, 942]</td>\n",
       "      <td>[0.014503473058081072, 0.014081669026719337, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[75, 612, 630, 5, 447]</td>\n",
       "      <td>[0.013194220385430996, 0.006735921388057532, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[662, 386, 22, 6, 367]</td>\n",
       "      <td>[0.008358809429052701, 0.0077694174533529375, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[191, 32, 68, 36, 103]</td>\n",
       "      <td>[0.005673865264351188, 0.005593071207467765, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[140, 350, 0, 198, 88]</td>\n",
       "      <td>[0.01117085137967383, 0.006446157617534622, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[24, 41, 89, 1, 3]</td>\n",
       "      <td>[0.00551614963053364, 0.004901551412492643, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[791, 952, 783, 619, 943]</td>\n",
       "      <td>[0.014395183124337957, 0.013483096723672138, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                termIndices   \n",
       "0      0    [178, 501, 16, 62, 160]  \\\n",
       "1      1    [300, 130, 42, 84, 426]   \n",
       "2      2      [5, 136, 10, 29, 251]   \n",
       "3      3    [22, 244, 85, 637, 942]   \n",
       "4      4     [75, 612, 630, 5, 447]   \n",
       "5      5     [662, 386, 22, 6, 367]   \n",
       "6      6     [191, 32, 68, 36, 103]   \n",
       "7      7     [140, 350, 0, 198, 88]   \n",
       "8      8         [24, 41, 89, 1, 3]   \n",
       "9      9  [791, 952, 783, 619, 943]   \n",
       "\n",
       "                                         termWeights  \n",
       "0  [0.017475817288113468, 0.008052443968767586, 0...  \n",
       "1  [0.007347377651882966, 0.0072655290516734005, ...  \n",
       "2  [0.008795192147850545, 0.006622747467534118, 0...  \n",
       "3  [0.014503473058081072, 0.014081669026719337, 0...  \n",
       "4  [0.013194220385430996, 0.006735921388057532, 0...  \n",
       "5  [0.008358809429052701, 0.0077694174533529375, ...  \n",
       "6  [0.005673865264351188, 0.005593071207467765, 0...  \n",
       "7  [0.01117085137967383, 0.006446157617534622, 0....  \n",
       "8  [0.00551614963053364, 0.004901551412492643, 0....  \n",
       "9  [0.014395183124337957, 0.013483096723672138, 0...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe topics\n",
    "topics = model.describeTopics(5)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['war', 'earth', 'films', 'world', 'american', 'japanese', 'history', 'black', 'human', 'story']\n",
      "['game', 'dvd', 'funny', 'comedy', 'jokes', 'great', 'know', 'saw', 'copy', 'original']\n",
      "['bad', 'worst', 'movies', 'ever', 'awful', 'waste', 'seen', 'plot', 'annoying', 'acting']\n",
      "['show', 'episode', 'series', 'season', 'park', 'government', 'episodes', 'love', 'strong', 'beautiful']\n",
      "['horror', 'red', 'match', 'bad', 'gore', 'sequel', 'little', 'kills', 'story', 'special']\n",
      "['french', 'girls', 'show', 'great', 'actress', 'characters', 'appreciate', 'performance', 'films', 'sister']\n",
      "['father', 'man', 'young', 'scene', 'family', 'woman', 'two', 'life', 'women', 'wife']\n",
      "['book', 'michael', 'story', 'read', 'role', 'love', 'interest', 'wife', 'director', 'silent']\n",
      "['love', 'didn', 'right', 'much', 'get', 'version', 'performance', 'people', 'best', 'think']\n",
      "['disney', 'gang', 'remake', 'rock', 'anti', 'original', 'crazy', 'office', 'killing', 'black']\n"
     ]
    }
   ],
   "source": [
    "# Print most important words per topic\n",
    "topics = model.describeTopics(10)\n",
    "for r in topics.select(\"termIndices\").collect():\n",
    "    rez = []\n",
    "    for l in r:\n",
    "        for i in l:\n",
    "            rez.append(vocabulary[i])\n",
    "    print(rez[:15])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic classification with LDA\n",
    "LDA can be a useful technique for text classification, especially when you want to identify the underlying topics within a corpus and classify documents into those topics.\n",
    "\n",
    "Advantages of using LDA for classification:\n",
    "- Identifies latent topics: LDA can automatically identify the underlying topics in a corpus of text. This can be useful for discovering hidden themes and patterns in the data.\n",
    "- Unsupervised learning: LDA is an unsupervised learning technique, which means that it does not require labeled data to identify the topics. This can save time and effort in preparing labeled data for training a classifier.\n",
    "- Handles high-dimensional data: LDA can handle high-dimensional data, such as text documents, by reducing the dimensionality of the data to a smaller set of topics.\n",
    "- Flexibility: LDA is a flexible technique that can be adapted to different types of text data and modeling assumptions.\n",
    "\n",
    "Problems of using LDA for classification:\n",
    "- Requires large data sets: LDA can require large data sets to accurately estimate the topic distributions. If the data set is too small, the resulting topic distributions may not be representative of the underlying data.\n",
    "- Sensitivity to model parameters: LDA is sensitive to the number of topics and other model parameters. Choosing the optimal number of topics can be challenging and requires some trial and error.\n",
    "- Limited interpretability: While LDA can identify latent topics, the resulting topics may not always be easily interpretable. It may require domain expertise to interpret the topics and assign meaningful labels to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_c</th>\n",
       "      <th>topicDistribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wonderful little production  The filming tec...</td>\n",
       "      <td>[0.0008763249135069179, 0.0009338337717097869,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably   all time favorite movie    story   ...</td>\n",
       "      <td>[0.24078093625857785, 0.0012578127791771474, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sure would like   see   resurrection       d...</td>\n",
       "      <td>[0.41490408010409824, 0.001052641424818598, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was   amazing  fresh  innovative ide...</td>\n",
       "      <td>[0.0006961678913543277, 0.0007418380658093587,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cast played Shakespeare Shakespeare lost  ...</td>\n",
       "      <td>[0.0010745360556843068, 0.0011450051012760047,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_c   \n",
       "0    wonderful little production  The filming tec...  \\\n",
       "1  Probably   all time favorite movie    story   ...   \n",
       "2    sure would like   see   resurrection       d...   \n",
       "3  This show was   amazing  fresh  innovative ide...   \n",
       "4  The cast played Shakespeare Shakespeare lost  ...   \n",
       "\n",
       "                                   topicDistribution  \n",
       "0  [0.0008763249135069179, 0.0009338337717097869,...  \n",
       "1  [0.24078093625857785, 0.0012578127791771474, 0...  \n",
       "2  [0.41490408010409824, 0.001052641424818598, 0....  \n",
       "3  [0.0006961678913543277, 0.0007418380658093587,...  \n",
       "4  [0.0010745360556843068, 0.0011450051012760047,...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows the result\n",
    "transformed = model.transform(dataset)\n",
    "transformed.select(\"text_c\",\"topicDistribution\").toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "@udf\n",
    "def vect_argmax(row):\n",
    "    row_arr = row.toArray()\n",
    "    max_pos = np.argmax(row_arr)\n",
    "    return(int(max_pos))\n",
    "transformed1 = transformed.withColumn(\"argmax\",vect_argmax(F.col('topicDistribution')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_c</th>\n",
       "      <th>argmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wonderful little production  The filming tec...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably   all time favorite movie    story   ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sure would like   see   resurrection       d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This show was   amazing  fresh  innovative ide...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The cast played Shakespeare Shakespeare lost  ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_c argmax\n",
       "0    wonderful little production  The filming tec...      6\n",
       "1  Probably   all time favorite movie    story   ...      8\n",
       "2    sure would like   see   resurrection       d...      0\n",
       "3  This show was   amazing  fresh  innovative ide...      3\n",
       "4  The cast played Shakespeare Shakespeare lost  ...      2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed1.select(\"text_c\",\"argmax\").toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9db6cbf0fd79f8e79653fe7b0c50b956ca6e525ee712295da3c66f75e4fe96ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
